{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "classify_electrocardiograms.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AurelSann/dotfiles/blob/master/classify_electrocardiograms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "M4N4IiMu8Oer"
      },
      "source": [
        "# Deep Learning - Day 4 - Classify Electrocardiograms\n",
        "\n",
        "### Exercise objectives:\n",
        "- Discover a new type of application with temporal data\n",
        "- Try different recurrent neural networks\n",
        "\n",
        "<hr>\n",
        "<hr>\n",
        "\n",
        "We have seen that RNN are able to predict what happens after an observed sequence of data. Let's see here a different way of using RNN. Instead of predicting a value that occurs after the seen sequence, we will here classify the entire sequence itself, as if the whole sequence corresponds to a given category. \n",
        "\n",
        "# Data\n",
        "\n",
        "The data corresponds to electrocardiograms (ECG), which are basically heart beats. Each sequence is therefore a sequence of amplitudes. These ECG are often used to observe heart malfunctions! In this dataset, there are 87554 heart beats and each corresponds to a heart beat type, from 0 to 4:\n",
        "- 0 : Normal beat\n",
        "- 1 : Supraventricular\n",
        "- 2 : Ventricular\n",
        "- 3 : Fusion\n",
        "- 4 : Beats that cannot be classified\n",
        "\n",
        "\n",
        "❓ **Question** ❓ Download the data from [here](https://storage.googleapis.com/data-sciences-bootcamp/ECG_data.zip), unzip them and read them thanks to the \n",
        "`np.load(path/to/data, allow_pickle=True).tolist()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTmCgnHv8YyE"
      },
      "source": [
        "# Nouvelle section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JBzk1wT8Oez"
      },
      "source": [
        "❓ **Question** ❓ Plot one ECG for each category in the dataset to see what an ECG looks like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGSNig0i8Oez",
        "outputId": "86117c04-d965-4013-b36c-cb3888b66269"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiygKLrQdsdk"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "X = np.load('drive/MyDrive/ECG_data/X.npy',allow_pickle=True).tolist()\n",
        "y = np.load('drive/MyDrive/ECG_data/y.npy',allow_pickle=True).tolist()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpqOhz5XdtFE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nq90QqZq8Oe0"
      },
      "source": [
        "❓ **Question** ❓ You have probably noticed that each sequence (each ECG) has a different length. To corroborate your observation, plot the distribution of the sequence lengths in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_8HDZdX8Oe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "bec74ab3-8e73-43cf-8134-e6149c4603fe"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.distplot([len(X[i]) for i in range(len(X))])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa0df09cd30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCU-xS37drXq"
      },
      "source": [
        ""
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kUHe7T38Oe0"
      },
      "source": [
        "\n",
        "\n",
        "You remember that we pass a batch of data to the neural network. Thus, the tensor will have the following shape (batch_size, number of sequences, number of observations per sequence, size of each observation).\n",
        "\n",
        "- The batch_size will be choosen in the model fit\n",
        "- There are 87554 sequences\n",
        "- Each observation is of size 1\n",
        "\n",
        "However, the number of observations per sequence vary from one sequence to another. For computational reasons, this cannot be feed into a RNN. For that reason, you need to \"fill in the blanks\" thanks to the `pad_sequences` so that each sequence is filled with fake values. The resulting sequences will all be of the same length.\n",
        "\n",
        "\n",
        "❓ **Question** ❓ Use the `pad_sequences` function on X directly (without extra arguments here), store the result in `X_pad` and print the first sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHGiGXRe8Oe1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "308ef296-b5e4-4280-dfe3-3957601c59a8"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "X_pad = pad_sequences(X, dtype='float32',value =-1,padding='post') \n",
        "X_pad"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.97794116,  0.9264706 ,  0.6813725 , ..., -1.        ,\n",
              "        -1.        , -1.        ],\n",
              "       [ 0.96011394,  0.8632479 ,  0.46153846, ..., -1.        ,\n",
              "        -1.        , -1.        ],\n",
              "       [ 1.        ,  0.6594595 ,  0.18648648, ..., -1.        ,\n",
              "        -1.        , -1.        ],\n",
              "       ...,\n",
              "       [ 0.90612245,  0.6244898 ,  0.59591836, ..., -1.        ,\n",
              "        -1.        , -1.        ],\n",
              "       [ 0.85822785,  0.6455696 ,  0.8455696 , ..., -1.        ,\n",
              "        -1.        , -1.        ],\n",
              "       [ 0.90150636,  0.84588647,  0.80069524, ..., -1.        ,\n",
              "        -1.        , -1.        ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPARySHY8Oe1"
      },
      "source": [
        "❓ **Question** ❓ You probably see that the returned sequence is composed only of 0's. The reason is because, by default, `pad_sequences` returns integers. If a float is between 0.0 and 0.99999, it is converted to 0. To change this default behavior, turn the `dtype` argument of `pad_sequences` to `float32`. Pad once again the sequences, store the new result in `X_pad` and print the first sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfUuEo4R8Oe1"
      },
      "source": [
        "import numpy as np\n",
        "X_pad=np.expand_dims(X_pad,axis=-1)\n",
        "assert(X_pad.shape == (87554, 187, 1))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOKiZJ-wnY53",
        "outputId": "918b88b6-691a-4099-f7cc-bf482eaa61e7"
      },
      "source": [
        "X_pad"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.97794116],\n",
              "        [ 0.9264706 ],\n",
              "        [ 0.6813725 ],\n",
              "        ...,\n",
              "        [-1.        ],\n",
              "        [-1.        ],\n",
              "        [-1.        ]],\n",
              "\n",
              "       [[ 0.96011394],\n",
              "        [ 0.8632479 ],\n",
              "        [ 0.46153846],\n",
              "        ...,\n",
              "        [-1.        ],\n",
              "        [-1.        ],\n",
              "        [-1.        ]],\n",
              "\n",
              "       [[ 1.        ],\n",
              "        [ 0.6594595 ],\n",
              "        [ 0.18648648],\n",
              "        ...,\n",
              "        [-1.        ],\n",
              "        [-1.        ],\n",
              "        [-1.        ]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 0.90612245],\n",
              "        [ 0.6244898 ],\n",
              "        [ 0.59591836],\n",
              "        ...,\n",
              "        [-1.        ],\n",
              "        [-1.        ],\n",
              "        [-1.        ]],\n",
              "\n",
              "       [[ 0.85822785],\n",
              "        [ 0.6455696 ],\n",
              "        [ 0.8455696 ],\n",
              "        ...,\n",
              "        [-1.        ],\n",
              "        [-1.        ],\n",
              "        [-1.        ]],\n",
              "\n",
              "       [[ 0.90150636],\n",
              "        [ 0.84588647],\n",
              "        [ 0.80069524],\n",
              "        ...,\n",
              "        [-1.        ],\n",
              "        [-1.        ],\n",
              "        [-1.        ]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxFYubC98Oe1"
      },
      "source": [
        "The neural network, thanks to a `Masking` layer, will remove the 0 that you padded for computational reasons. \n",
        "\n",
        "**However**, if you look closely at the padded version of the first sequence, you have the padded zeros at the beginning of the sequence. But, also, there is a 0 value **_IN_** the heart-beat values. \n",
        "How could the neural network know which one to keep and which one to remove?\n",
        "\n",
        "❓ **Question** ❓ Add the `value` keyword in the `pad_sequences` function to pad with values that **ARE NOT** in the initial dataset. Negative values for instance. Store it in `X_pad` and print the first sequence.\n",
        "\n",
        "❗ **Remark** ❗ This is a good habit to pad the values **at the end** of the sequence (instead of the beginning as it is done by default). You can do that thanks to the `padding` keyword set to `post` (instead of `pre` by default).\n",
        "\n",
        "[See full documentation here](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrdGFT3s8Oe2"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y_cat = to_categorical(y)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbLaDXa38Oe2"
      },
      "source": [
        "❓ **Question** ❓ Plot the shape of `X_pad`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2tWAf_28Oe2"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test =train_test_split(X_pad,y_cat,train_size=0.8)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paaSnQ7pneMp",
        "outputId": "890e58f4-ff00-427a-a0ce-5d779b58d26e"
      },
      "source": [
        "type(X_pad)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSJbFxts8Oe2"
      },
      "source": [
        "Remember that we said that the input data have to be of shape (number of sequences, number of observations per sequence, observation size) [Apart from the batch size dimention which will be automatically added by the Neural Network] ? Here, we only have the two first dimensions. This is because the last dimension is of size 1. \n",
        "\n",
        "❓ **Question** ❓ To remedy this issue, expand the last dimension thanks to the `np.expand_dims` function. \n",
        "\n",
        "❗ **Remark** ❗ The assert should not return any error ;)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kbk3JVO8Oe3"
      },
      "source": [
        "### YOUD CODE HERE\n",
        "\n",
        "assert(X_pad.shape == (87554, 187, 1))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c42605d020fd51885437f4af3cf10cebbeafc9bb",
        "id": "4pM2Av_E8Oe3"
      },
      "source": [
        "❓ **Question** ❓ The labels `y` have to be one-hot encoded categories. For that reason, transform them to categories thanks to the appropriate Keras function and store the result in `y_cat`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2DZaEjy8Oe3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2824fd76-0047-42d3-b765-ed163a0647f2"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.8603696 ],\n",
              "        [ 0.56057495],\n",
              "        [ 0.16221766],\n",
              "        ...,\n",
              "        [-1.        ],\n",
              "        [-1.        ],\n",
              "        [-1.        ]],\n",
              "\n",
              "       [[ 1.        ],\n",
              "        [ 0.9316667 ],\n",
              "        [ 0.75333333],\n",
              "        ...,\n",
              "        [-1.        ],\n",
              "        [-1.        ],\n",
              "        [-1.        ]],\n",
              "\n",
              "       [[ 0.93786985],\n",
              "        [ 0.8165681 ],\n",
              "        [ 0.30473372],\n",
              "        ...,\n",
              "        [-1.        ],\n",
              "        [-1.        ],\n",
              "        [-1.        ]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 0.8126411 ],\n",
              "        [ 0.7325056 ],\n",
              "        [ 0.41647854],\n",
              "        ...,\n",
              "        [-1.        ],\n",
              "        [-1.        ],\n",
              "        [-1.        ]],\n",
              "\n",
              "       [[ 1.        ],\n",
              "        [ 0.8305785 ],\n",
              "        [ 0.42975205],\n",
              "        ...,\n",
              "        [-1.        ],\n",
              "        [-1.        ],\n",
              "        [-1.        ]],\n",
              "\n",
              "       [[ 1.        ],\n",
              "        [ 0.8996139 ],\n",
              "        [ 0.63706565],\n",
              "        ...,\n",
              "        [-1.        ],\n",
              "        [-1.        ],\n",
              "        [-1.        ]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "7ae5108c9741b85f0f599cce51daf99df4733ed1",
        "id": "RT4BJUpR8Oe3"
      },
      "source": [
        "❓ **Question** ❓ Split your data between a train and test set (80/20 ratio)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "cbd350e57b2a44b4bf6a79f02c32dabb803e4855",
        "id": "PQoFh73a8Oe3"
      },
      "source": [
        "### YOUR CODE HERE"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c4de23b85abe34a726eab268171da0e827bafa35",
        "id": "v5pKRvNL8Oe4"
      },
      "source": [
        "# Model\n",
        "\n",
        "We will now write the Recurrent Neural Network\n",
        "\n",
        "❓ **Question** ❓ Write model that has the following layers:\n",
        "- a Masking layer whose `mask_value` corresponds to the value you decided to pad your data with (it is probably a negative value as suggested) - this layer will simply tell the network not to take into account the computation artifact\n",
        "- a `SimpleRNN` layer with 10 units and the `tanh` as the activation function\n",
        "- a dense layer with 20 units\n",
        "- a last layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-osR8F18flJ"
      },
      "source": [
        "# Nouvelle section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M8x_UHu8Oe4"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def init_model():\n",
        "    model = Sequential()\n",
        "    model.add(layers.Masking(mask_value=-1))\n",
        "    model.add(layers.SimpleRNN(units=20, activation='tanh')) \n",
        "    model.add(layers.Dense(10, activation=\"relu\"))\n",
        "    model.add(layers.Dense(5,activation='softmax'))\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LudncCErfmoc"
      },
      "source": [
        "model = init_model()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APE-WyrP8Oe4"
      },
      "source": [
        "❓ **Question** ❓ Compile your model and train it - a very small patience equal to 2 should be sufficient. This is because you have a lot of sequences and thus, many optimizations per epochs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBphF_Hd8Oe4"
      },
      "source": [
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF7L28t-f6Nq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f7c7600-183d-47af-8e3b-adf333ff6ada"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70043, 187, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_tJy8aSf62a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed935a6d-4d6b-457c-f1b5-d2f47fc5b499"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "es = EarlyStopping(patience=2,restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train,y_train,\n",
        "                   validation_split =0.2,\n",
        "                   callbacks=[es],\n",
        "                   epochs=300, \n",
        "                  batch_size=16,\n",
        "                  verbose=1\n",
        "                  )\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "3503/3503 [==============================] - 171s 48ms/step - loss: 0.6813 - accuracy: 0.8233 - val_loss: 0.6542 - val_accuracy: 0.8303\n",
            "Epoch 2/300\n",
            "3503/3503 [==============================] - 164s 47ms/step - loss: 0.6662 - accuracy: 0.8250 - val_loss: 0.6539 - val_accuracy: 0.8303\n",
            "Epoch 3/300\n",
            "3503/3503 [==============================] - 158s 45ms/step - loss: 0.6559 - accuracy: 0.8289 - val_loss: 0.6492 - val_accuracy: 0.8303\n",
            "Epoch 4/300\n",
            "3503/3503 [==============================] - 162s 46ms/step - loss: 0.6607 - accuracy: 0.8277 - val_loss: 0.6496 - val_accuracy: 0.8303\n",
            "Epoch 5/300\n",
            "3503/3503 [==============================] - 159s 46ms/step - loss: 0.6632 - accuracy: 0.8267 - val_loss: 0.6545 - val_accuracy: 0.8303\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQFBmun-8Oe4"
      },
      "source": [
        "❓ **Question** ❓ Evaluate your model on the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyndCYQA8Oe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f1bf30b-eecc-43e8-f937-471f04d5ea67"
      },
      "source": [
        "model.evaluate(X_test,y_test)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "548/548 [==============================] - 6s 12ms/step - loss: 0.6618 - accuracy: 0.8263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6618326902389526, 0.8262805938720703]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RifVt8D8Oe5"
      },
      "source": [
        "### You should be have quite promising results with a test accuracy a little higher than 80%, which is a good result on a 5-class problem.\n",
        "\n",
        "❓ **Question** ❓ Let's try to improve this result. Repeat the last steps by using a `LSTM` instead of a `SimpleRNN`. If you feel like it, you can change the neural network parameters to improve the accuracy. Evaluate your accuracy on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lvluwey8Oe5"
      },
      "source": [
        "def init_model2():\n",
        "    model = Sequential()\n",
        "    model.add(layers.Masking(mask_value=-1))\n",
        "    model.add(layers.LSTM(units=20, activation='tanh')) \n",
        "    model.add(layers.Dense(10, activation=\"relu\"))\n",
        "    model.add(layers.Dense(5,activation='softmax'))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTBS_lIBrUj8"
      },
      "source": [
        "model2 = init_model2()"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OZ3XpCCrXQK"
      },
      "source": [
        "model2.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzzlrmqjrayy",
        "outputId": "b6cc6535-daff-40dc-86d9-c8615231db4e"
      },
      "source": [
        "history = model2.fit(X_train,y_train,\n",
        "                   validation_split =0.2,\n",
        "                   callbacks=[es],\n",
        "                   epochs=300, \n",
        "                  batch_size=16,\n",
        "                  verbose=1\n",
        "                  )"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "3503/3503 [==============================] - 289s 81ms/step - loss: 0.7726 - accuracy: 0.7868 - val_loss: 0.6524 - val_accuracy: 0.8303\n",
            "Epoch 2/300\n",
            "3503/3503 [==============================] - 285s 81ms/step - loss: 0.6661 - accuracy: 0.8251 - val_loss: 0.6485 - val_accuracy: 0.8303\n",
            "Epoch 3/300\n",
            "3503/3503 [==============================] - 287s 82ms/step - loss: 0.6631 - accuracy: 0.8263 - val_loss: 0.6487 - val_accuracy: 0.8303\n",
            "Epoch 4/300\n",
            "3503/3503 [==============================] - 286s 82ms/step - loss: 0.6514 - accuracy: 0.8302 - val_loss: 0.6484 - val_accuracy: 0.8303\n",
            "Epoch 5/300\n",
            "3503/3503 [==============================] - 284s 81ms/step - loss: 0.6656 - accuracy: 0.8251 - val_loss: 0.6484 - val_accuracy: 0.8303\n",
            "Epoch 6/300\n",
            "3503/3503 [==============================] - 286s 82ms/step - loss: 0.6533 - accuracy: 0.8294 - val_loss: 0.6484 - val_accuracy: 0.8303\n",
            "Epoch 7/300\n",
            "3503/3503 [==============================] - 281s 80ms/step - loss: 0.6727 - accuracy: 0.8222 - val_loss: 0.6490 - val_accuracy: 0.8303\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDIDNOfX8Oe5"
      },
      "source": [
        "Quite surprisingly, the LSTM is not much better than the SimpleRNN. What about a GRU?\n",
        "\n",
        "❓ **Question** ❓ Build another model where you will use a GRU (instead of the LSTM or of the SimpleRNN), and the parameters are yours to choose. Report the test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ao_1Lfq8Oe5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5538d669-4290-45bd-a3e4-c2a9e4f78e26"
      },
      "source": [
        "model2.evaluate(X_test,y_test)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "548/548 [==============================] - 12s 22ms/step - loss: 0.6613 - accuracy: 0.8263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6613496541976929, 0.8262805938720703]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALqU1zw68Oe5"
      },
      "source": [
        "Once again, the final accuracy is likely to be similar to the one you got previously, which might be a bit strange. To investigate these results, we will compare the results to a baseline model.\n",
        "\n",
        "❓ **Question** ❓ What is the accuracy of a baseline model which would predict, for `y_test`, the most probable category in y_train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcaaDaBA8Oe5"
      },
      "source": [
        "### YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITDQgtxL8Oe6"
      },
      "source": [
        "Basically, your RNNs are as good (bad?) as a model that predicts the most present category. The reason is probably because the RNNs really return only the most present category.\n",
        "\n",
        "❓ **Question** ❓ Use the `predict` function on any of the previous model to see what are the different categories the model is predicting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpr9fzTM8Oe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3119aff2-e48c-4cec-f439-0a29e9d79279"
      },
      "source": [
        "model2.predict(y_test[76])"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 187, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 187, 1), dtype=tf.float32, name='masking_6_input'), name='masking_6_input', description=\"created by layer 'masking_6_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.468283  , 0.12274607, 0.16973774, 0.05387805, 0.18535517],\n",
              "       [0.4510793 , 0.12710065, 0.17174158, 0.06002973, 0.19004877],\n",
              "       [0.4510793 , 0.12710065, 0.17174158, 0.06002973, 0.19004877],\n",
              "       [0.4510793 , 0.12710065, 0.17174158, 0.06002973, 0.19004877],\n",
              "       [0.4510793 , 0.12710065, 0.17174158, 0.06002973, 0.19004877]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moJkTt4Q8Oe6"
      },
      "source": [
        "Your models are returning the category which is the most present in your train set. \n",
        "\n",
        "A possibility here is to either subsample the data to have balanced classes in the training set. Another possibility is to do some data augmentation on temporal data. However, none of these methods would work right away. In fact, predicting the category of ECG data is not an easy task - also, you have only **one** heart-beat, no repetitions of them! \n",
        "\n",
        "Classifying ECG is actually quite a complex task. So let's move on to another exercise. \n",
        "\n",
        "**The lesson here is not to be satisfied with results until you have compare them to a baseline method.**"
      ]
    }
  ]
}